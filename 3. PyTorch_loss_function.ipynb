{"cells":[{"cell_type":"markdown","metadata":{"id":"E6FUMb7jjKID"},"source":["# PyTorch loss functions\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n"]},{"cell_type":"markdown","metadata":{"id":"r3SUVFgDXUzn"},"source":["####  Mean Absolute Error (L1 Loss)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708989000874,"user":{"displayName":"Raman Goyal","userId":"02525396431054586688"},"user_tz":480},"id":"H_IA8ZaKaRLk","outputId":"789c6da0-4562-4944-fcf9-cc6b3df525e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE error is: 0.049999999999999996\n","MAE error is: 0.049999999999999996\n"]}],"source":["### Algorthmic way of find loss without pytorch module\n","y_pred = np.array([0.000, 0.100, 0.200])\n","y_true = np.array([0.000, 0.200, 0.250])\n","# Defining Mean Absolute Error loss function\n","def mae(pred, true):\n","    # Find absolute difference\n","    differences = pred - true\n","    absolute_differences = np.abs(differences)\n","    # find the absoute mean\n","    mean_absolute_error = absolute_differences.mean()\n","    return mean_absolute_error\n","mae_value = mae(y_pred, y_true)\n","print (f\"MAE error is: {mae_value}\")\n","\n","### With pytorch module\n","mae_loss = nn.L1Loss()\n","# input = torch.tensor(y_pred)\n","input = torch.from_numpy(y_pred)\n","target = torch.tensor(y_true)\n","output = mae_loss(input, target)\n","print (f\"MAE error is: {output}\")\n"]},{"cell_type":"markdown","metadata":{"id":"hswYi06WXY_Y"},"source":["####  Mean-Squared Error (L2 Loss)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8b2cA7uZ65T","outputId":"c32316ec-0a91-4150-b336-c3b0379451d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["input:  tensor([[ 0.7515, -1.4013,  0.0203, -0.9031],\n","        [-1.0604, -0.3901,  0.1571,  0.4864],\n","        [ 0.0177, -1.5536,  0.8002,  1.5735]])\n","target:  tensor([[-0.0104, -0.5732, -1.9517,  0.1279],\n","        [ 1.2443,  1.3559,  0.7180,  1.2573],\n","        [ 0.1096, -0.1976,  0.0757,  0.9563]])\n","output:  tensor(1.5200)\n"]}],"source":["input = torch.randn(3, 4)\n","target = torch.randn(3, 4)\n","\n","mse_loss = nn.MSELoss()\n","\n","output = mse_loss(input, target)\n","\n","print('input: ', input)\n","print('target: ', target)\n","print('output: ', output)"]},{"cell_type":"markdown","metadata":{"id":"GjwtuBsEXZTh"},"source":["####  Binary Cross Entropy\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fb6Ev6VMffV-","outputId":"cf989d97-7ce9-46d4-aa16-1b3efb1e0090"},"outputs":[{"name":"stdout","output_type":"stream","text":["BCE error is: 0.43800269247783435\n","BCE error is: 0.43800269247783435\n"]}],"source":["y_pred = np.array([0.1580, 0.4137, 0.2285])\n","y_true = np.array([0.0, 1.0, 0.0]) #2 labels: (0,1)\n","def BCE(y_pred, y_true):\n","    total_bce_loss = np.sum(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n","    # Getting the mean BCE loss\n","    num_of_samples = y_pred.shape[0]\n","    mean_bce_loss = total_bce_loss / num_of_samples\n","\n","    return mean_bce_loss\n","\n","bce_value = BCE(y_pred, y_true)\n","print (f\"BCE error is: {bce_value}\")\n","\n","### With pytorch implemenation\n"," \n","bce_loss = torch.nn.BCELoss()\n","sigmoid = torch.nn.Sigmoid() # Ensuring inputs are between 0 and 1\n","input = torch.tensor(y_pred)\n","target = torch.tensor(y_true)\n","output = bce_loss(input, target)\n","print (f\"BCE error is: {output}\")"]},{"cell_type":"markdown","metadata":{"id":"kMqXnUB8tg_w"},"source":["#### BCEWithLogitsLoss (nn.BCEWithLogitsLoss)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zfpYHGjjHqP","outputId":"76415ba8-ec05-4ecf-a9be-04a82d1313c9"},"outputs":[{"data":{"text/plain":["tensor(0.2014)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n","output = torch.full([10, 64], 1.5)  # A prediction (logit)\n","pos_weight = torch.ones([64])  # All weights are equal to 1\n","criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","criterion(output, target)  # -log(sigmoid(1.5))"]},{"cell_type":"markdown","metadata":{"id":"i1lc02NDYZOs"},"source":["#### Negative Log-Likelihood Loss\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpPl1N89fI4Y","outputId":"766fde07-a229-45ce-8202-eba0721859e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["input -:  tensor([[ 0.4240, -0.8866,  0.3379,  0.4667,  1.9522],\n","        [-1.7342, -1.3068,  0.6175, -1.0443,  0.1609],\n","        [-0.6249,  1.6715,  0.4174, -0.7046, -0.7868]], requires_grad=True)\n","target -:  tensor([1, 0, 4])\n","output -:  tensor(3.1174, grad_fn=<NllLossBackward0>)\n"]}],"source":["input = torch.randn(3, 5, requires_grad=True)\n","# every element in target should have value(0 <= value < C)\n","target = torch.tensor([1, 0, 4])\n","\n","m = nn.LogSoftmax(dim=1)\n","nll_loss = nn.NLLLoss()\n","output = nll_loss(m(input), target)\n","output.backward()\n","\n","print('input -: ', input)\n","print('target -: ', target)\n","print('output -: ', output)"]},{"cell_type":"markdown","metadata":{"id":"OLIpmLghtjwe"},"source":["#### PoissonNLLLoss"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7MB8eCbtVC-","outputId":"733e1ec0-e091-4a05-8f7a-f61016e505ed"},"outputs":[{"data":{"text/plain":["tensor(2.9496, grad_fn=<MeanBackward0>)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["import torch.nn as nn\n","loss = nn.PoissonNLLLoss()\n","log_input = torch.randn(5, 2, requires_grad=True)\n","target = torch.randn(5, 2)\n","output = loss(log_input, target)\n","output.backward()\n","output"]},{"cell_type":"markdown","metadata":{"id":"gXZXFzi5YgJM"},"source":["#### Cross-Entropy Loss\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mYMGOXthk8p","outputId":"00dc8cf0-d433-4d2a-f734-0fd6f0076028"},"outputs":[{"name":"stdout","output_type":"stream","text":["input:  tensor([[ 0.4668, -0.7414,  0.3209, -0.3085,  0.8684],\n","        [ 0.0124,  1.1104, -0.0532, -0.8222,  0.7659],\n","        [ 1.3226, -1.4100,  0.7760, -2.0372, -0.3903]], requires_grad=True)\n","target:  tensor([1, 2, 3])\n","output:  tensor(2.8943, grad_fn=<NllLossBackward0>)\n"]}],"source":["input = torch.randn(3, 5, requires_grad=True)\n","target = torch.empty(3, dtype=torch.long).random_(5)\n","\n","cross_entropy_loss = nn.CrossEntropyLoss()\n","output = cross_entropy_loss(input, target)\n","output.backward()\n","\n","print('input: ', input)\n","print('target: ', target)\n","print('output: ', output)"]},{"cell_type":"markdown","metadata":{"id":"O9dASCuufNvP"},"source":["#### Hinge Embedding Loss\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfStGspphvwy","outputId":"6dc99ac5-10f6-4e74-a3ac-55d624547c89"},"outputs":[{"name":"stdout","output_type":"stream","text":["input -:  tensor([[ 1.0623,  1.2043,  1.4614, -0.2002,  0.8756],\n","        [-0.4214, -0.2845, -1.0520, -0.2945, -0.5903],\n","        [-1.7936, -1.5658,  0.8501,  2.0940, -0.7442]], requires_grad=True)\n","target -:  tensor([[-1.3354, -0.3173, -0.8452, -1.3085, -0.2188],\n","        [-0.8100, -0.4166, -1.5621, -1.0632,  0.0192],\n","        [ 1.6360,  1.2752,  1.6695,  0.3429, -0.5284]])\n","output -:  tensor(1.1215, grad_fn=<MeanBackward0>)\n"]}],"source":["input = torch.randn(3, 5, requires_grad=True)\n","target = torch.randn(3, 5)\n","\n","hinge_loss = nn.HingeEmbeddingLoss()\n","output = hinge_loss(input, target)\n","output.backward()\n","\n","print('input -: ', input)\n","print('target -: ', target)\n","print('output -: ', output)"]},{"cell_type":"markdown","metadata":{"id":"tKJ72jDeYonF"},"source":["#### Margin Ranking Loss"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyN0cc1GiEZE","outputId":"7fdba3d7-00ac-49af-dd0f-c36f1f829cf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["input one:  tensor([-0.2863,  1.2897,  1.3833], requires_grad=True)\n","input two:  tensor([ 0.3334,  1.2730, -0.6828], requires_grad=True)\n","target:  tensor([ 1.,  1., -1.])\n","output:  tensor(0.8953, grad_fn=<MeanBackward0>)\n"]}],"source":["first_input = torch.randn(3, requires_grad=True)\n","Second_input = torch.randn(3, requires_grad=True)\n","target = torch.randn(3).sign()\n","\n","ranking_loss = nn.MarginRankingLoss()\n","output = ranking_loss(first_input, Second_input, target)\n","output.backward()\n","\n","print('input one: ', first_input)\n","print('input two: ', Second_input)\n","print('target: ', target)\n","print('output: ', output)"]},{"cell_type":"markdown","metadata":{"id":"c0--iv1UidaY"},"source":["#### Triplet Margin Loss Function"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-VV1XSNihPT","outputId":"d5add53c-177b-4e43-d88f-087a938dd4f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["anchors -:  tensor([[ 2.4030,  0.3069, -0.3384,  ..., -0.6177,  1.2326, -0.0830],\n","        [ 1.0934, -0.1223, -0.5555,  ..., -1.0320,  1.7122,  0.1484],\n","        [ 1.1761,  2.2152, -1.5984,  ..., -0.1161,  0.3179, -1.4899],\n","        ...,\n","        [-0.6451, -0.9723, -0.3063,  ...,  1.6396, -0.3455, -0.5605],\n","        [ 1.3400, -1.0634,  0.4573,  ..., -0.1895, -0.8853, -0.6858],\n","        [-1.1754, -0.1079, -0.6117,  ..., -0.4233, -2.3889, -0.5540]],\n","       requires_grad=True)\n","positive -:  tensor([[-0.2379, -0.5866,  0.7631,  ...,  0.3578,  0.4019,  2.1400],\n","        [-1.2937,  0.0805, -0.4508,  ..., -1.1977, -0.1506, -0.3858],\n","        [-0.8930,  0.9101,  0.0022,  ..., -0.3918, -1.1427,  0.2395],\n","        ...,\n","        [ 0.3817,  1.1141, -1.3956,  ...,  0.3665,  0.6505, -1.1218],\n","        [-1.0313,  1.6796, -0.4631,  ..., -0.2304, -0.5800,  0.8109],\n","        [-1.9683, -1.4422, -0.5480,  ..., -1.2838,  0.3712,  1.5779]],\n","       requires_grad=True)\n","negative -:  tensor([[ 0.2854, -0.1462, -1.1070,  ...,  0.5352, -0.3443,  0.1069],\n","        [ 1.3907,  0.0605, -1.4622,  ..., -0.4663, -0.2843,  0.4608],\n","        [ 0.5006,  0.2438, -1.9095,  ..., -1.7024, -0.1158,  2.9640],\n","        ...,\n","        [-1.7392,  1.0843, -1.3466,  ...,  0.2896, -1.6346, -0.4005],\n","        [-0.5727, -1.4714, -0.9236,  ...,  1.3322, -0.2044,  1.3019],\n","        [-1.3903, -0.1107, -0.8794,  ...,  1.2829,  1.1448, -0.2485]],\n","       requires_grad=True)\n","output -:  tensor(1.0572, grad_fn=<MeanBackward0>)\n"]}],"source":["anchor = torch.randn(100, 128, requires_grad=True)\n","positive = torch.randn(100, 128, requires_grad=True)\n","negative = torch.randn(100, 128, requires_grad=True)\n","\n","triplet_margin_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n","output = triplet_margin_loss(anchor, positive, negative)\n","output.backward()\n","\n","print('anchors -: ', anchor)\n","print('positive -: ', positive)\n","print('negative -: ', negative)\n","print('output -: ', output)"]},{"cell_type":"markdown","metadata":{"id":"6KX_8Ym8YjJl"},"source":["#### Kullback-Leibler divergence\n"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpnNQ0TpXHLz","outputId":"2d7b6d1a-1e3f-4e7a-b277-deade7439f72"},"outputs":[{"name":"stdout","output_type":"stream","text":["input tensor:  tensor([[ 0.6550,  0.1223,  1.7807],\n","        [-1.0974, -2.1969,  0.9264]], requires_grad=True)\n","target tensor:  tensor([[ 1.0080, -3.3751,  0.5746],\n","        [-0.0309,  1.6132, -1.8930]])\n","Loss:  tensor(nan, grad_fn=<DivBackward0>)\n"]}],"source":["input = torch.randn(2, 3, requires_grad=True)\n","target = torch.randn(2, 3)\n","\n","kld_loss = nn.KLDivLoss(reduction = 'batchmean')\n","output = kld_loss(input, target)\n","output.backward()\n","\n","print('input tensor: ', input)\n","print('target tensor: ', target)\n","print('Loss: ', output)"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mmaithani/data-science/blob/main/PyTorch_ALL_loss_function.ipynb","timestamp":1708988668433}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
